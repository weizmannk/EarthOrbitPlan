#!/usr/bin/env python
"""
postproces.py: Compute Detection Probabilities and Extract Metrics
==============================================================================

This script processes observation plans generated by M4OPT, computing detection
probabilities and extracting relevant optimization metrics.

It supports both command-line arguments and `.ini` configuration files.

Usage
-----
From the command line:

    python postprocess_schedules.py  --data-dir data

Or using a config file:

    python postprocess_schedules.py --config params_ultrasat.ini


This process will compute the detctection probaility using the detection_probability.py and collect all the needed and store together all the data from the simulation
in and `events.ecsv` file located in the data_dir, in default : ./data. Then you could use it
latter for future statistic processing .
"""

import argparse
import configparser
import logging
import sys
from pathlib import Path

from astropy.table import QTable
from detection_probability import get_detection_probability_known_position
from ligo.skymap.util.progress import progress_map


def parse_arguments():
    """
    Parse command-line arguments or load them from a .ini configuration file.
    Returns
    -------
    argparse.Namespace
        The parsed arguments.
    """
    parser = argparse.ArgumentParser(description="Post-process M4OPT ECSV plans.")
    parser.add_argument("--config", type=str, help="Path to .ini configuration file")

    args, remaining_args = parser.parse_known_args()

    if args.config:
        config = configparser.ConfigParser()
        config.read(args.config)
        cfg = config["params"]
        return argparse.Namespace(
            data_dir=cfg.get("data_dir", fallback="data"),
            event_table=cfg.get("event_table", fallback="observing-scenarios.ecsv"),
            output_file=cfg.get("output_file", fallback="events.ecsv"),
            sched_dir=cfg.get("sched_dir", fallback="schedules"),
        )

    # CLI parsing if no config
    parser.add_argument(
        "--data-dir", type=str, default="data", help="Directory containing ECSV files"
    )
    parser.add_argument(
        "--event-table",
        type=str,
        default="observing-scenarios.ecsv",
        help="Input summary table",
    )
    parser.add_argument(
        "--output-file", type=str, default="events.ecsv", help="Output filename"
    )
    parser.add_argument(
        "--sched-dir", type=str, default="schedules", help="Schedule directory"
    )

    return parser.parse_args(remaining_args)


def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[logging.StreamHandler(sys.stdout)],
        force=True,
    )


def process(row, sched_path):
    run = row["run"]
    event_id = row["coinc_event_id"]
    plan_file = sched_path / run / f"{event_id}.ecsv"

    if not plan_file.exists():
        logging.warning(f"Missing schedule file: {plan_file}")
        return (None, None, None, None, None, None)

    plan = QTable.read(plan_file)
    plan_args = {**plan.meta["args"]}
    plan_args.pop("skymap", None)
    return (
        get_detection_probability_known_position(plan, row, plan_args),
        plan.meta.get("objective_value"),
        plan.meta.get("best_bound"),
        plan.meta.get("solution_status"),
        plan.meta.get("solution_time"),
        len(plan[plan["action"] == "observe"]) // plan_args["visits"],
    )


def main():
    args = parse_arguments()
    setup_logging()

    base_path = Path(args.data_dir)
    input_path = base_path / args.event_table
    sched_path = base_path / args.sched_dir
    output_path = base_path / args.output_file

    logging.info(f"Reading input table from {input_path}")
    table = QTable.read(input_path)

    logging.info("Processing observation plans...")
    (
        table["detection_probability_known_position"],
        table["objective_value"],
        table["best_bound"],
        table["solution_status"],
        table["solution_time"],
        table["num_fields"],
    ) = zip(*progress_map(lambda row: process(row, sched_path), table))

    logging.info(f"Writing results to {output_path}")
    table.write(output_path, overwrite=True)


if __name__ == "__main__":
    main()

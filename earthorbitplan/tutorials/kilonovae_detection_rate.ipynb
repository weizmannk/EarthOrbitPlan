{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Installation & Setup (Colab only) ---\n",
    "# Clone our GitHub repository into the Colab environment\n",
    "\n",
    "import sys\n",
    "\n",
    "# Check if the env run under Colab\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/weizmannk/EarthOrbitPlan.git\n",
    "    %cd EarthOrbitPlan\n",
    "    !pip install -e .\n",
    "\n",
    "    print(\"Environment ready. You can now run the rest of the notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if the env run under Colab\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Go to the \"EarthOrbitPlan/earthorbitplan/tutorials\"\n",
    "    os.chdir(\"./earthorbitplan/tutorials\")\n",
    "\n",
    "    # Check if the 'kilonovae_detection_rate.ipynb' is there\n",
    "    print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress known warnings for cleaner output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "warnings.filterwarnings(\"ignore\", \".*dubious year.*\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \"Tried to get polar motions for times after IERS data is valid.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from astropy.table import QTable\n",
    "from IPython.display import Math, display\n",
    "from scipy import stats\n",
    "\n",
    "from earthorbitplan.probability.rate import poisson_lognormal_rate_quantiles\n",
    "from earthorbitplan.utils.path import get_project_root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Setup logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"cwd =\", os.getcwd())\n",
    "print(\n",
    "    \"events.ecsv exists?\", os.path.exists(\"../../data/events_ultrasat_non_overlap.ecsv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Load simulated event data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = get_project_root()\n",
    "events_file = root / \"data\" / \"events_ultrasat_non_overlap.ecsv\"\n",
    "main_table = QTable.read(events_file)\n",
    "\n",
    "events_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Get unique run names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = np.unique(main_table[\"run\"])\n",
    "\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Filter events by objective_value cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = main_table[\"cutoff\"][0]\n",
    "main_table = main_table[main_table[\"objective_value\"] >= cutoff]\n",
    "main_table[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Group events by run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_tables_by_run = {run: main_table[main_table[\"run\"] == run] for run in runs}\n",
    "event_tables_by_run[runs[0]][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Set merger rate priors from O3 R&P Table II (last column)\n",
    "\n",
    "This section explains how we reproduce the 5%, 50%, and 95% quantiles of the BNS and NSBH merger rate, \n",
    "\n",
    "as reported in [O3 R&P, Table II](https://doi.org/10.1103/PhysRevX.13.011048), for our own simulation statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Reported CBC merger rates:\n",
    "\n",
    "- **5% quantile:** 100 $\\mathrm{Gpc}^{-3}\\ \\mathrm{yr}^{-1} $\n",
    "\n",
    "- **50% quantile (median):** 240 $\\mathrm{Gpc}^{-3}\\ \\mathrm{yr}^{-1} $\n",
    "\n",
    "- **95% quantile:** 510 $\\mathrm{Gpc}^{-3}\\ \\mathrm{yr}^{-1} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, mid, hi = 100, 240, 510  # In Gpc^-3 yr^-1\n",
    "\n",
    "# 90% interval width (in log-normal)\n",
    "(standard_90pct_interval,) = np.diff(stats.norm.interval(0.9))\n",
    "log_target_rate_mu = np.log(mid)\n",
    "log_target_rate_sigma = np.log(hi / lo) / standard_90pct_interval\n",
    "\n",
    "print(log_target_rate_mu, log_target_rate_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Compute effective rate for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get effective rate for each run\n",
    "\n",
    "log_simulation_effective_rate_by_run = {\n",
    "    key: np.log(value.to_value(u.Gpc**-3 * u.yr**-1))\n",
    "    for key, value in main_table.meta[\"effective_rate\"].items()\n",
    "}\n",
    "log_simulation_effective_rate_by_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Compute median ($\\mu$) and quantiles for each run  : $\\mu$ is calculated for each simulation run as:\n",
    "\n",
    "$\n",
    "\\mu = \\log(\\text{target median}) + \\log(\\text{run duration}) - \\log(\\text{simulation effective rate}) + \\log(\\text{N or detected N})\n",
    "$\n",
    "\n",
    "Here we use both number of events and number detected (with known position).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_quantiles = np.asarray([0.5, 0.05, 0.95])  # median, 5%, 95%\n",
    "run_duration = 0.5  # years\n",
    "\n",
    "mu = np.asarray(\n",
    "    [\n",
    "        log_target_rate_mu\n",
    "        + np.log(run_duration)\n",
    "        - log_simulation_effective_rate_by_run[run]\n",
    "        + np.log(\n",
    "            [\n",
    "                np.sum(_)\n",
    "                for _ in [\n",
    "                    np.ones_like(event_tables_by_run[run][\"objective_value\"]),\n",
    "                    event_tables_by_run[run][\"detection_probability_known_position\"],\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "        for run in runs\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "labels = [\"All selected\", \"Detected known position\"]\n",
    "display(Math(r\"\\mu\\ \\mathrm{values\\ per\\ run:}\"))\n",
    "\n",
    "for run, vals in zip(runs, mu):\n",
    "    for label, v in zip(labels, vals):\n",
    "        safe_label = label.replace(\" \", \"~\")\n",
    "        display(Math(rf\"{run}~\\mathrm{{({safe_label})}}:~{v:.3f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Compute Poisson-Lognormal rate quantiles for all runs\n",
    "\n",
    "This step calculates the quantile intervals for the merger rates for all runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_quantiles = poisson_lognormal_rate_quantiles(\n",
    "    prob_quantiles[np.newaxis, np.newaxis, :],\n",
    "    mu.T[:, :, np.newaxis],\n",
    "    log_target_rate_sigma,\n",
    ")\n",
    "\n",
    "\n",
    "quantile_labels = [\"Median\", \"5%\", \"95%\"]\n",
    "idx = 0\n",
    "\n",
    "print(f\"Quantiles for the run {runs[idx]}:\")\n",
    "# Print column headers\n",
    "print(\"  {:<25} {:>8} {:>8} {:>8}\".format(\"Type\", *quantile_labels))\n",
    "for label, row in zip(labels, rate_quantiles[idx]):\n",
    "    print(\"  {:<25} {:>8.2f} {:>8.2f} {:>8.2f}\".format(label, *row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Detection  and Selected Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rst_table(headers, rows):\n",
    "    columns = [headers] + rows\n",
    "    n_cols = len(headers)\n",
    "    col_widths = [max(len(str(row[i])) for row in columns) for i in range(n_cols)]\n",
    "\n",
    "    def sep(char=\"+\", fill=\"-\"):\n",
    "        return char + char.join(fill * (w + 2) for w in col_widths) + char\n",
    "\n",
    "    def fmt_row(row):\n",
    "        return (\n",
    "            \"| \"\n",
    "            + \" | \".join(str(cell).ljust(w) for cell, w in zip(row, col_widths))\n",
    "            + \" |\"\n",
    "        )\n",
    "\n",
    "    lines = [\n",
    "        sep(),\n",
    "        fmt_row(headers),\n",
    "        sep(\"=\", \"=\"),\n",
    "    ]\n",
    "    for row in rows:\n",
    "        lines.append(fmt_row(row))\n",
    "        lines.append(sep())\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# Prepare headers and format quantile results\n",
    "headers = [\"Run\"] + list(runs)\n",
    "labels = [\"Number of events selected\", \"Number of events detected\"]\n",
    "rst_rows = []\n",
    "\n",
    "for label, row in zip(labels, rate_quantiles):\n",
    "    formatted = [\n",
    "        \"${}_{{-{}}}^{{+{}}}$\".format(*np.rint([mid, mid - lo, hi - mid]).astype(int))\n",
    "        for mid, lo, hi in row\n",
    "    ]\n",
    "    rst_rows.append([label] + formatted)\n",
    "\n",
    "rst_table = make_rst_table(headers, rst_rows)\n",
    "\n",
    "# Print the table\n",
    "print(rst_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from earthorbitplan.utils.path import get_project_root\n",
    "from earthorbitplan.workflow.area_distance import plot_area_distance\n",
    "\n",
    "root = get_project_root()\n",
    "events_file = root / \"data\" / \"events_ultrasat_non_overlap.ecsv\"\n",
    "plot_area_distance(events_file, show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earthorbitplan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
